{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding model...  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Warning: hipconfig --rocmpath failed, assuming /opt/rocm\n",
      "Done\n",
      "Load vector store...  Done\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "vector_store_path = 'vector_store'\n",
    "EB_PATH = r'D:\\Huan\\Project\\KHDL\\model\\ebmodel\\bge-m3-ft-triplet'\n",
    "re = retrieve(vector_store_path = vector_store_path, EMBEDDING_MODEL_PATH = EB_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá truy xuất trên 10 dữ liệu đầu tiên\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"qs_context.jsonl\", \"r\", encoding='utf-8') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "    \n",
    "retrieved_contexts = [[j.page_content for j in re.similarity_search(query=i['Question'], top_k=10)] for i in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(retrieved_contexts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MRR@10: 0.7552\n",
      "Mean Recall@10: 0.9168\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_mrr(retrieved_contexts, relevant):\n",
    "    \"\"\"Tính MRR@10.\"\"\"\n",
    "    for rank, context in enumerate(retrieved_contexts[:10], 1):\n",
    "        if context == relevant:  # context đúng là context duy nhất trong relevant\n",
    "            return 1 / rank\n",
    "    return 0  # Nếu không tìm thấy kết quả đúng trong 10 truy xuất\n",
    "\n",
    "def calculate_recall(retrieved_contexts, relevant):\n",
    "    \"\"\"Tính Recall@10.\"\"\"\n",
    "    relevant_retrieved = [context for context in retrieved_contexts[:10] if context == relevant]\n",
    "    return len(relevant_retrieved) / 1  # Vì chỉ có 1 context đúng trong relevant\n",
    "\n",
    "\n",
    "# Khởi tạo các danh sách để lưu kết quả\n",
    "mrr_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Tính toán các chỉ số cho mỗi câu hỏi\n",
    "for i in range(len(data)):\n",
    "    retrieved = retrieved_contexts[i]\n",
    "    relevant = data[i]['Context']\n",
    "    \n",
    "    # Tính MRR@10\n",
    "    mrr_scores.append(calculate_mrr(retrieved, relevant))\n",
    "    \n",
    "    # Tính Recall@10\n",
    "    recall_scores.append(calculate_recall(retrieved, relevant))\n",
    "\n",
    "# Tính giá trị trung bình của các chỉ số\n",
    "mean_mrr = np.mean(mrr_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "\n",
    "print(f\"Mean MRR@10: {mean_mrr:.4f}\")\n",
    "print(f\"Mean Recall@10: {mean_recall:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

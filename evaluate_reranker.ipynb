{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding model...  WARNING:tensorflow:From d:\\Python\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Done\n",
      "Load vector store...  Done\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "re = retrieve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load reranker model... Done\n"
     ]
    }
   ],
   "source": [
    "from rerank import reranker\n",
    "_reranker = reranker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá truy xuất trên 10 dữ liệu đầu tiên\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import concurrent.futures\n",
    "\n",
    "# Đọc dữ liệu từ file JSONL\n",
    "with open(\"qs_context.jsonl\", \"r\", encoding='utf-8') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Hàm để rerank cho từng truy vấn\n",
    "def rerank_for_query(query_data):\n",
    "    query = query_data['Question']\n",
    "    contexts = [j.page_content for j in re.similarity_search(query=query, top_k=10)]\n",
    "    return _reranker.rerank(query=query, contexts=contexts)[0]\n",
    "\n",
    "# Sử dụng ThreadPoolExecutor hoặc ProcessPoolExecutor để chạy song song\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    retrieved_contexts = list(executor.map(rerank_for_query, data))\n",
    "\n",
    "# retrieved_contexts sẽ chứa kết quả cho tất cả các truy vấn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(retrieved_contexts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MRR@10: 0.7552\n",
      "Mean Recall@10: 0.9168\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_mrr(retrieved_contexts, relevant):\n",
    "    \"\"\"Tính MRR@10.\"\"\"\n",
    "    for rank, context in enumerate(retrieved_contexts[:10], 1):\n",
    "        if context == relevant:  # context đúng là context duy nhất trong relevant\n",
    "            return 1 / rank\n",
    "    return 0  # Nếu không tìm thấy kết quả đúng trong 10 truy xuất\n",
    "\n",
    "def calculate_recall(retrieved_contexts, relevant):\n",
    "    \"\"\"Tính Recall@10.\"\"\"\n",
    "    relevant_retrieved = [context for context in retrieved_contexts[:10] if context == relevant]\n",
    "    return len(relevant_retrieved) / 1  # Vì chỉ có 1 context đúng trong relevant\n",
    "\n",
    "\n",
    "# Khởi tạo các danh sách để lưu kết quả\n",
    "mrr_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Tính toán các chỉ số cho mỗi câu hỏi\n",
    "for i in range(len(data)):\n",
    "    retrieved = retrieved_contexts[i]\n",
    "    relevant = data[i]['Context']\n",
    "    \n",
    "    # Tính MRR@10\n",
    "    mrr_scores.append(calculate_mrr(retrieved, relevant))\n",
    "    \n",
    "    # Tính Recall@10\n",
    "    recall_scores.append(calculate_recall(retrieved, relevant))\n",
    "\n",
    "# Tính giá trị trung bình của các chỉ số\n",
    "mean_mrr = np.mean(mrr_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "\n",
    "print(f\"Mean MRR@10: {mean_mrr:.4f}\")\n",
    "print(f\"Mean Recall@10: {mean_recall:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
